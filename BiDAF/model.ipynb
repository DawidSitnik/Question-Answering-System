{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.platform import gfile\n",
    "import logging\n",
    "import time\n",
    "import tensorflow_addons as tfa\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "logging.basicConfig(stream = sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_epochs = 30\n",
    "    batch_size = 32\n",
    "    train_embeddings=0\n",
    "    max_gradient_norm=-1\n",
    "    hidden_state_size=150\n",
    "    embedding_size=50\n",
    "    data_dir=\"data/preprocessed\"\n",
    "    vocab_path=\"vocabulary/vocab.dat\"\n",
    "    embed_path=\"glove_vectors/_vectors.npz\"\n",
    "    dropout_val=1.0\n",
    "    train_dir=\"models_lstm_basic\"\n",
    "    use_match=0\n",
    "    \n",
    "\n",
    "    def get_paths(mode):\n",
    "        question = \"data/preprocessed/\"+str(mode)+\".ids.question\" \n",
    "        context = \"data/preprocessed/\"+str(mode)+\".ids.context\" \n",
    "        answer = \"data/preprocessed/\"+str(mode)+\".span\"\n",
    "\n",
    "        return question, context, answer \n",
    "\n",
    "    question_train, context_train, answer_train = get_paths(\"train\")\n",
    "    question_dev ,context_dev ,answer_dev = get_paths(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squad_dataset(object):\n",
    "    def __init__(self, question_file, context_file, answer_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filename: path to the files\n",
    "        \"\"\"\n",
    "        self.question_file = question_file\n",
    "        self.context_file = context_file\n",
    "        self.answer_file = answer_file\n",
    "\n",
    "        self.length = None\n",
    "\n",
    "    def iter_file(self, filename):\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                line = line.strip().split(\" \")\n",
    "                line = map(lambda tok: int(tok), line)\n",
    "                yield line\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        niter = 0\n",
    "\n",
    "        question_file_iter = self.iter_file(self.question_file)\n",
    "        answer_file_iter = self.iter_file(self.answer_file)\n",
    "        context_file_iter = self.iter_file(self.context_file)\n",
    "\n",
    "        for question, context, answer in zip(question_file_iter, context_file_iter, answer_file_iter):\n",
    "            yield list(question),list(context), list(answer)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Iterates once over the corpus to set and store length\n",
    "        \"\"\"\n",
    "        if self.length is None:\n",
    "            self.length = 0\n",
    "            for _ in self:\n",
    "                self.length += 1\n",
    "\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trimmed_glove_vectors(filename):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filename: path to the npz file\n",
    "    Returns:\n",
    "        nmatrix of embeddings (np array)\n",
    "    \"\"\"\n",
    "    return np.load(filename)[\"glove\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vocab(vocab_path):\n",
    "    if gfile.Exists(vocab_path):\n",
    "        rev_vocab = [] \n",
    "        with tf.io.gfile.GFile(vocab_path, mode=\"rb\") as f:\n",
    "            rev_vocab.extend(f.readlines())\n",
    "        rev_vocab = [line.strip(b'\\n') for line in rev_vocab]\n",
    "        vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\n",
    "        return vocab, rev_vocab\n",
    "    else:\n",
    "        raise ValueError(\"Vocabulary file %s not found.\", vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "train = squad_dataset(config.question_train, config.context_train, config.answer_train)\n",
    "dev = squad_dataset(config.question_dev, config.context_dev, config.answer_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_dictonary(vocab):\n",
    "    dict_1 = {}\n",
    "    i=0\n",
    "    for k in vocab:\n",
    "        k = re.sub(r'.*b\\'', '\\'', str(k)).replace('\\'','')\n",
    "        dict_1.update({k:i})\n",
    "        i+=1\n",
    "    return dict_1\n",
    "\n",
    "def clear_list(dirty_list):\n",
    "    clean_list = []\n",
    "    for x in dirty_list:\n",
    "        clean_list.append(re.sub(r'.*b\\'', '\\'', str(x)).replace('\\'',''))\n",
    "    return clean_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = config.embed_path\n",
    "vocab_path = config.vocab_path\n",
    "vocab, rev_vocab = initialize_vocab(vocab_path)\n",
    "vocab1 = clear_dictonary(vocab)\n",
    "rev_vocab1 = clear_list(rev_vocab)\n",
    "embeddings = get_trimmed_glove_vectors(embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_sequences(sequences, pad_tok, max_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    sequence_padded, sequence_length = [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        seq = list(seq)\n",
    "        seq_ = seq[:max_length] + [pad_tok]*max(max_length - len(seq), 0)\n",
    "        sequence_padded +=  [seq_]\n",
    "        sequence_length += [min(len(seq), max_length)]\n",
    "\n",
    "    return np.array(sequence_padded), np.array(sequence_length)\n",
    "\n",
    "def pad_sequences(sequences, pad_tok):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sequences: a generator of list or tuple\n",
    "        pad_tok: the char to pad with\n",
    "    Returns:\n",
    "        a list of list where each sublist has same length\n",
    "    \"\"\"\n",
    "    max_length = max([len(list(x)) for x in sequences])\n",
    "    sequence_padded, sequence_length = _pad_sequences(sequences, \n",
    "                                            pad_tok, max_length)\n",
    "\n",
    "    return sequence_padded, sequence_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "question_ids = tf.placeholder(tf.int32, shape = [None, None], name = \"question_ids\")\n",
    "passage_ids = tf.placeholder(tf.int32, shape = [None, None], name = \"passage_ids\")\n",
    "\n",
    "question_lengths = tf.placeholder(tf.int32, shape=[None], name=\"question_lengths\")\n",
    "passage_lengths = tf.placeholder(tf.int32, shape = [None], name = \"passage_lengths\")\n",
    "\n",
    "labels = tf.placeholder(tf.int32, shape = [None, 2], name = \"gold_labels\")\n",
    "dropout = tf.placeholder(tf.float32, shape=[], name = \"dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(questions, contexts, answers, dropout_val):\n",
    "    \"\"\"\n",
    "    -arg questions: A list of list of ids representing the question sentence\n",
    "    -arg contexts: A list of list of ids representing the context paragraph\n",
    "    -arg dropout_val: A float representing the keep probability for dropout \n",
    "\n",
    "    :return: dict {placeholders: value}\n",
    "    \"\"\"\n",
    "\n",
    "    padded_questions, question_length = pad_sequences(questions, 0)\n",
    "    padded_contexts, passage_length = pad_sequences(contexts, 0)\n",
    "\n",
    "\n",
    "    feed = {\n",
    "        question_ids : padded_questions,\n",
    "        passage_ids : padded_contexts,\n",
    "        question_lengths : question_length,\n",
    "        passage_lengths : passage_length,\n",
    "        labels : answers,\n",
    "        dropout : dropout_val\n",
    "    }\n",
    "\n",
    "    return feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-446d869b27fc>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-13-446d869b27fc>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"vocab_embeddings\"):\n",
    "    _word_embeddings = tf.Variable(embeddings, name=\"_word_embeddings\", dtype=tf.float32, trainable= config.train_embeddings)\n",
    "    question_emb = tf.nn.embedding_lookup(_word_embeddings, question_ids, name = \"question\") # (-1, Q, D)\n",
    "    passage_emb = tf.nn.embedding_lookup(_word_embeddings, passage_ids, name = \"passage\") # (-1, P, D)\n",
    "    # Apply dropout\n",
    "    question = tf.nn.dropout(question_emb, config.dropout_val)\n",
    "    passage  = tf.nn.dropout(passage_emb, config.dropout_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(inputs, masks, encoder_state_input = None):\n",
    "    \"\"\"\n",
    "    :param inputs: vector representations of question and passage (a tuple) \n",
    "    :param masks: masking sequences for both question and passage (a tuple)\n",
    "\n",
    "    :param encoder_state_input: (Optional) pass this as initial hidden state\n",
    "                                to tf.nn.dynamic_rnn to build conditional representations\n",
    "    :return: an encoded representation of the question and passage.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    question, passage = inputs\n",
    "    masks_question, masks_passage = masks    \n",
    "\n",
    "    # read passage conditioned upon the question\n",
    "    with tf.variable_scope(\"encoded_question\"):\n",
    "        lstm_cell_fw_question = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_cell_bw_question = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        encoded_question, (q_rep, _) = tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_question, lstm_cell_bw_question, question, masks_question, dtype=tf.float32) # (-1, Q, H)\n",
    "\n",
    "    with tf.variable_scope(\"encoded_passage\"):\n",
    "        lstm_cell_fw_passage  = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_cell_bw_passage  = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        encoded_passage, (p_rep, _) =   tf.nn.bidirectional_dynamic_rnn(lstm_cell_fw_passage, lstm_cell_bw_passage, passage, masks_passage, dtype=tf.float32) # (-1, P, H)\n",
    "\n",
    "    # Merging both the outputs of the bi-lstm models\n",
    "    encoded_question = tf.concat(axis = 2, values = encoded_question)\n",
    "    encoded_passage = tf.concat(axis = 2, values = encoded_passage)\n",
    "\n",
    "    # outputs beyond sequence lengths are masked with 0s\n",
    "    return encoded_question, encoded_passage , q_rep, p_rep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reverse(input_, seq_lengths, seq_dim, batch_dim):\n",
    "    if seq_lengths is not None:\n",
    "        return array_ops.reverse_sequence(\n",
    "            input=input_, seq_lengths=seq_lengths,\n",
    "            seq_dim=seq_dim, batch_dim=batch_dim)\n",
    "    else:\n",
    "        return array_ops.reverse(input_, axis=[seq_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match LSTM\n",
    "def run_match_lstm(encoded_rep, masks):\n",
    "    encoded_question, encoded_passage = encoded_rep\n",
    "    masks_question, masks_passage = masks\n",
    "    \n",
    "    match_lstm_cell_attention_fn = lambda curr_input, state : tf.concat([curr_input, state], axis = -1)\n",
    "    query_depth = encoded_question.get_shape()[-1]\n",
    "\n",
    "    with tf.variable_scope(\"match_lstm_attender\"):\n",
    "        attention_mechanism_match_lstm = tfa.seq2seq.BahdanauAttention(query_depth, encoded_question, memory_sequence_length = masks_question)\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple = True)\n",
    "        lstm_attender  =  tfa.seq2seq.AttentionWrapper(cell, attention_mechanism_match_lstm, output_attention = False, cell_input_fn = match_lstm_cell_attention_fn)\n",
    "    \n",
    "        # we don't mask the passage because masking the memories will be handled by the pointerNet\n",
    "        reverse_encoded_passage = _reverse(encoded_passage, masks_passage, 1, 0)\n",
    "    \n",
    "        output_attender_fw, _ = tf.nn.dynamic_rnn(lstm_attender, encoded_passage, dtype=tf.float32, scope =\"rnn\")    \n",
    "        output_attender_bw, _ = tf.nn.dynamic_rnn(lstm_attender, reverse_encoded_passage, dtype=tf.float32, scope = \"rnn\")\n",
    "    \n",
    "        output_attender_bw = _reverse(output_attender_bw, masks_passage, 1, 0)\n",
    "    \n",
    "    output_attender = tf.concat([output_attender_fw, output_attender_bw], axis = -1) # (-1, P, 2*H)\n",
    "    return output_attender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Pointer\n",
    "def run_answer_ptr(output_attender, masks, labels):\n",
    "    #batch_size = tf.shape(output_attender)[0]\n",
    "    masks_question, masks_passage = masks\n",
    "    labels = tf.unstack(labels, axis=1) \n",
    "    \n",
    "    answer_ptr_cell_input_fn = lambda curr_input, context : context # independent of question\n",
    "    query_depth_answer_ptr = output_attender.get_shape()[-1]\n",
    "    \n",
    "    with tf.variable_scope(\"answer_ptr_attender\"):\n",
    "        attention_mechanism_answer_ptr = tfa.seq2seq.BahdanauAttention(query_depth_answer_ptr , output_attender, memory_sequence_length = masks_passage)\n",
    "    \n",
    "        # output attention is true because we want to output the attention values\n",
    "        cell_answer_ptr = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, state_is_tuple = True )\n",
    "        answer_ptr_attender = tfa.seq2seq.AttentionWrapper(cell_answer_ptr, attention_mechanism_answer_ptr, cell_input_fn = answer_ptr_cell_input_fn)\n",
    "        logits, _ = tf.nn.static_rnn(answer_ptr_attender, labels, dtype = tf.float32)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "def decode(encoded_rep, q_rep, masks, labels):\n",
    "    \"\"\"\n",
    "    takes in a knowledge representation\n",
    "    and output a probability estimation over\n",
    "    all paragraph tokens on which token should be\n",
    "    the start of the answer span, and which should be\n",
    "    the end of the answer span.\n",
    "\n",
    "    :param knowledge_rep: it is a representation of the paragraph and question,\n",
    "                          decided by how you choose to implement the encoder\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Run match-LSTM + Ans-Ptr\n",
    "    output_attender = run_match_lstm(encoded_rep, masks)\n",
    "    logits = run_answer_ptr(output_attender, masks, labels)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1fe81d491049>:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-1fe81d491049>:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-1fe81d491049>:19: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-15-1fe81d491049>:19: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-16-e4997021fa19>:5: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From <ipython-input-16-e4997021fa19>:5: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From <ipython-input-18-a0bf69569baa>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-18-a0bf69569baa>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-18-a0bf69569baa>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-18-a0bf69569baa>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "# setup_system\n",
    "encoded_question, encoded_passage, q_rep, p_rep = encode([question,passage], [question_lengths,passage_lengths],encoder_state_input = None)\n",
    "encoded_rep = encoded_question, encoded_passage\n",
    "masks = question_lengths,passage_lengths\n",
    "logits = decode(encoded_rep, q_rep, masks, labels)\n",
    "\n",
    "# setup_loss\n",
    "losses= tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[0], labels=labels[:,0])\n",
    "losses+= tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[1], labels=labels[:,1])\n",
    "loss = tf.reduce_mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
